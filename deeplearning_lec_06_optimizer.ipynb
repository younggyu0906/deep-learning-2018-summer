{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YGKIM\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras import\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Sklearn import\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_train type: <class 'numpy.ndarray'>\n",
      "y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "num_classes = 10\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_train type: {}\".format(type(X_train)))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (60000, 10)\n",
      "y_test shape: (10000, 10)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\YGKIM\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\YGKIM\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#Two-Layer Network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3595 - acc: 0.8983\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1594 - acc: 0.9531\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1189 - acc: 0.9648\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0940 - acc: 0.9718\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0772 - acc: 0.9766\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0663 - acc: 0.9802\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0575 - acc: 0.9822\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0482 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0424 - acc: 0.9869\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0360 - acc: 0.9894\n",
      "End Time:  29.673668146133423\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"End Time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### without batch normalization\n",
    "model = Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(Dense(64, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Hidden layer\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3603 - acc: 0.8992\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1530 - acc: 0.9545\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.1104 - acc: 0.9666\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0866 - acc: 0.9736\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0720 - acc: 0.9775\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0601 - acc: 0.9817\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0525 - acc: 0.9842\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0452 - acc: 0.9859\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0391 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0334 - acc: 0.9899\n",
      "End Time:  27.784837245941162\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"End Time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### with bath normalization\n",
    "model = Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(Dense(64, input_shape=(784,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Hidden layer\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.3264 - acc: 0.9085\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1240 - acc: 0.9631\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0878 - acc: 0.9740\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0693 - acc: 0.9786\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0557 - acc: 0.9821\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0487 - acc: 0.9843\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0405 - acc: 0.9876\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0345 - acc: 0.9891\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0310 - acc: 0.9901\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0279 - acc: 0.9916\n",
      "End Time:  40.358068227767944\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=100,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"End Time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### initializer\n",
    "def create_model(init='zeros'):\n",
    "    model = Sequential()\n",
    "\n",
    "    #input layer\n",
    "    model.add(Dense(64, kernel_initializer=init, input_shape=(784,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #Hidden layer\n",
    "    model.add(Dense(64, kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "                loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'init': ['zeros', 'ones', 'glorot_uniform', 'normal', 'uniform'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 2.3019 - acc: 0.1093\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 2.3015 - acc: 0.1106\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 2.3016 - acc: 0.1106\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 2.3016 - acc: 0.1106\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 2.3015 - acc: 0.1106\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 2.3015 - acc: 0.1106\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 2.3015 - acc: 0.1106\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 2.3015 - acc: 0.1106\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 2.3016 - acc: 0.1106\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 2.3015 - acc: 0.1106\n",
      "30000/30000 [==============================] - 2s 55us/step\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 253us/step - loss: 2.3015 - acc: 0.1138\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 2.3011 - acc: 0.1141\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 2.3011 - acc: 0.1141\n",
      "30000/30000 [==============================] - 2s 60us/step\n",
      "30000/30000 [==============================] - 2s 57us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 8s 261us/step - loss: 2.0961 - acc: 0.2291\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 1.5594 - acc: 0.4706\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 1.1681 - acc: 0.6054\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.9842 - acc: 0.6553\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.9092 - acc: 0.6814\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.8664 - acc: 0.7005\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.8410 - acc: 0.7104\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.8138 - acc: 0.7161\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.7940 - acc: 0.7259\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.7749 - acc: 0.7317\n",
      "30000/30000 [==============================] - 2s 57us/step\n",
      "30000/30000 [==============================] - 2s 52us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 2.1221 - acc: 0.2239\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 1.7069 - acc: 0.4026\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 1.3443 - acc: 0.5354\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 1.1260 - acc: 0.5966\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 1.0204 - acc: 0.6349\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.9360 - acc: 0.6706\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.8812 - acc: 0.6908\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.8443 - acc: 0.7009\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.8192 - acc: 0.7107\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.8031 - acc: 0.7185\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "30000/30000 [==============================] - 2s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.3770 - acc: 0.8913\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.1708 - acc: 0.9487\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.1303 - acc: 0.9601\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.1035 - acc: 0.9678\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0851 - acc: 0.9719\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0748 - acc: 0.9753\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0658 - acc: 0.9786\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0579 - acc: 0.9817\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0545 - acc: 0.9822\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0486 - acc: 0.9837\n",
      "30000/30000 [==============================] - 2s 66us/step\n",
      "30000/30000 [==============================] - 2s 54us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.3820 - acc: 0.8933\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.1641 - acc: 0.9500\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.1206 - acc: 0.9627\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0969 - acc: 0.9693\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0807 - acc: 0.9738\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0704 - acc: 0.9776\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0645 - acc: 0.9791\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0575 - acc: 0.9812\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0524 - acc: 0.9824\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0474 - acc: 0.9834\n",
      "30000/30000 [==============================] - 2s 65us/step\n",
      "30000/30000 [==============================] - 2s 55us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.3558 - acc: 0.8999\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.1673 - acc: 0.9489\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.1208 - acc: 0.9622\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0990 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0865 - acc: 0.9725\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0750 - acc: 0.9754\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0669 - acc: 0.9791\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0578 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0538 - acc: 0.9823\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0515 - acc: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 66us/step\n",
      "30000/30000 [==============================] - 2s 53us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 184us/step - loss: 0.3604 - acc: 0.8975\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.1554 - acc: 0.9527\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.1174 - acc: 0.9627\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0959 - acc: 0.9686\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0822 - acc: 0.9734\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0719 - acc: 0.9756\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0630 - acc: 0.9801\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0557 - acc: 0.9813\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0474 - acc: 0.9844\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0461 - acc: 0.9845\n",
      "30000/30000 [==============================] - 2s 69us/step\n",
      "30000/30000 [==============================] - 2s 56us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 191us/step - loss: 0.3239 - acc: 0.9074\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.1606 - acc: 0.9504\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.1172 - acc: 0.9640\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0997 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0825 - acc: 0.9744\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0734 - acc: 0.9765\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0658 - acc: 0.9783\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0559 - acc: 0.9812\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0504 - acc: 0.9839\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0479 - acc: 0.9841\n",
      "30000/30000 [==============================] - 2s 71us/step\n",
      "30000/30000 [==============================] - 2s 59us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 6s 210us/step - loss: 0.3218 - acc: 0.9078\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.1464 - acc: 0.9558\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.1140 - acc: 0.9646\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0927 - acc: 0.9704\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.0824 - acc: 0.9732\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0680 - acc: 0.9788\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0613 - acc: 0.9798\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0546 - acc: 0.9817\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0448 - acc: 0.9854\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0504 - acc: 0.9829\n",
      "30000/30000 [==============================] - 2s 77us/step\n",
      "30000/30000 [==============================] - 2s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,562\n",
      "Trainable params: 55,306\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.2521 - acc: 0.9256\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1279 - acc: 0.9608\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1019 - acc: 0.9682\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0826 - acc: 0.9734\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0740 - acc: 0.9758\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0662 - acc: 0.9782\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0584 - acc: 0.9806\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0554 - acc: 0.9819\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0504 - acc: 0.9829\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0459 - acc: 0.9851\n",
      "Best: 0.970000 using {'init': 'uniform'}\n",
      "0.112367 (0.001733) with: {'init': 'zeros'}\n",
      "0.764167 (0.005267) with: {'init': 'ones'}\n",
      "0.968100 (0.000567) with: {'init': 'glorot_uniform'}\n",
      "0.969633 (0.000933) with: {'init': 'normal'}\n",
      "0.970000 (0.001267) with: {'init': 'uniform'}\n",
      "End Time:  686.130140542984\n"
     ]
    }
   ],
   "source": [
    "start_timestart_ti  = time.time()\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, cv=2, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print(\"End Time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
